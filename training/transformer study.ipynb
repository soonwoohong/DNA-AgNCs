{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ypdiGkRZdkgs-aKYOTnRtzDU-SroJPc5","authorship_tag":"ABX9TyMtCHid4gHnySinaAlmOP0S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"UFl9by-kZlYM","executionInfo":{"status":"ok","timestamp":1675377311633,"user_tz":360,"elapsed":4147,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}}},"outputs":[],"source":["# example about compact convolutional transfomrers\n","# https://keras.io/examples/vision/cct/ by Sayak Paul\n","\n","\n","\n","# import packages\n","!pip install -U -q tensorflow-addons\n","\n","\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","import matplotlib.pyplot as plt\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","import numpy as np\n"]},{"cell_type":"code","source":["\n","positional_emb = True\n","conv_layers = 2\n","projection_dim = 128\n","\n","num_heads = 2\n","transformer_units = [\n","    projection_dim,\n","    projection_dim,\n","]\n","transformer_layers = 2\n","stochastic_depth_rate = 0.1\n","\n","learning_rate = 0.001\n","weight_decay = 0.0001\n","batch_size = 128\n","num_epochs = 30\n","image_size = 32\n","\n"],"metadata":{"id":"G3-sIx9xhANs","executionInfo":{"status":"ok","timestamp":1675377781314,"user_tz":360,"elapsed":99,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["num_classes = 10\n","input_shape = (32, 32, 3)\n","\n","(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n","\n","y_train = keras.utils.to_categorical(y_train, num_classes) # one-hot label\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n","print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRA17XC7QoKN","executionInfo":{"status":"ok","timestamp":1675377783016,"user_tz":360,"elapsed":1117,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}},"outputId":"f3b349ca-30d3-45c4-9d8e-d53c1a4cb884"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 10)\n","x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 10)\n"]}]},{"cell_type":"code","source":["class CCTTokenizer(layers.Layer):\n","    def __init__(\n","        self,\n","        kernel_size=3,\n","        stride=1,\n","        padding=1,\n","        pooling_kernel_size=3,\n","        pooling_stride=2,\n","        num_conv_layers=conv_layers,\n","        num_output_channels=[64, 128],\n","        positional_emb=positional_emb,\n","        **kwargs,\n","    ):\n","        super().__init__(**kwargs)\n","\n","        # This is our tokenizer.\n","        self.conv_model = keras.Sequential()\n","        for i in range(num_conv_layers):\n","            self.conv_model.add(\n","                layers.Conv2D(\n","                    num_output_channels[i],\n","                    kernel_size,\n","                    stride,\n","                    padding=\"valid\",\n","                    use_bias=False,\n","                    activation=\"relu\",\n","                    kernel_initializer=\"he_normal\",\n","                )\n","            )\n","            self.conv_model.add(layers.ZeroPadding2D(padding))\n","            self.conv_model.add(\n","                layers.MaxPool2D(pooling_kernel_size, pooling_stride, \"same\")\n","            )\n","\n","        self.positional_emb = positional_emb\n","\n","    def call(self, images):\n","        outputs = self.conv_model(images)\n","        # After passing the images through our mini-network the spatial dimensions\n","        # are flattened to form sequences.\n","        reshaped = tf.reshape(\n","            outputs,\n","            (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[-1]),\n","        )\n","        return reshaped\n","\n","    def positional_embedding(self, image_size):\n","        # Positional embeddings are optional in CCT. Here, we calculate\n","        # the number of sequences and initialize an `Embedding` layer to\n","        # compute the positional embeddings later.\n","        if self.positional_emb:\n","            dummy_inputs = tf.ones((1, image_size, image_size, 3))\n","            dummy_outputs = self.call(dummy_inputs)\n","            sequence_length = tf.shape(dummy_outputs)[1]\n","            projection_dim = tf.shape(dummy_outputs)[-1]\n","\n","            embed_layer = layers.Embedding(\n","                input_dim=sequence_length, output_dim=projection_dim\n","            )\n","            return embed_layer, sequence_length\n","        else:\n","            return None"],"metadata":{"id":"zF12r_-vRVod","executionInfo":{"status":"ok","timestamp":1675377792930,"user_tz":360,"elapsed":112,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#Stochastic depth is a regularization technique that randomly drops a set of layers. \n","#During inference, the layers are kept as they are. \n","#It is very much similar to Dropout \n","#but only that it operates on a block of layers rather than individual nodes present inside a layer. \n","#In CCT, stochastic depth is used just before the residual blocks of a Transformers encoder.\n","\n","# Referred from: github.com:rwightman/pytorch-image-models.\n","class StochasticDepth(layers.Layer):\n","    def __init__(self, drop_prop, **kwargs):\n","        super().__init__(**kwargs)\n","        self.drop_prob = drop_prop\n","\n","    def call(self, x, training=None):\n","        if training:\n","            keep_prob = 1 - self.drop_prob\n","            shape = (tf.shape(x)[0],) + (1,) * (tf.shape(x).shape[0] - 1)\n","            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n","            random_tensor = tf.floor(random_tensor)\n","            return (x / keep_prob) * random_tensor\n","        return x"],"metadata":{"id":"insY7vxPRhYd","executionInfo":{"status":"ok","timestamp":1675377818819,"user_tz":360,"elapsed":120,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x"],"metadata":{"id":"NACfn35OTLtv","executionInfo":{"status":"ok","timestamp":1675377825631,"user_tz":360,"elapsed":95,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Note the rescaling layer. These layers have pre-defined inference behavior.\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.Rescaling(scale=1.0 / 255),\n","        layers.RandomCrop(image_size, image_size),\n","        layers.RandomFlip(\"horizontal\"),\n","    ],\n","    name=\"data_augmentation\",\n",")"],"metadata":{"id":"i0RZEUpITNY1","executionInfo":{"status":"ok","timestamp":1675377914810,"user_tz":360,"elapsed":376,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def create_cct_model(\n","    image_size=image_size,\n","    input_shape=input_shape,\n","    num_heads=num_heads,\n","    projection_dim=projection_dim,\n","    transformer_units=transformer_units,\n","):\n","\n","    inputs = layers.Input(input_shape)\n","\n","    # Augment data.\n","    augmented = data_augmentation(inputs)\n","\n","    # Encode patches.\n","    cct_tokenizer = CCTTokenizer()\n","    encoded_patches = cct_tokenizer(augmented)\n","\n","    # Apply positional embedding.\n","    if positional_emb:\n","        pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n","        positions = tf.range(start=0, limit=seq_length, delta=1)\n","        position_embeddings = pos_embed(positions)\n","        encoded_patches += position_embeddings\n","\n","    # Calculate Stochastic Depth probabilities.\n","    dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n","\n","    # Create multiple layers of the Transformer block.\n","    for i in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n","\n","        # Create a multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","\n","        # Skip connection 1.\n","        attention_output = StochasticDepth(dpr[i])(attention_output)\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-5)(x2)\n","\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","\n","        # Skip connection 2.\n","        x3 = StochasticDepth(dpr[i])(x3)\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Apply sequence pooling.\n","    representation = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n","    attention_weights = tf.nn.softmax(layers.Dense(1)(representation), axis=1)\n","    weighted_representation = tf.matmul(\n","        attention_weights, representation, transpose_a=True\n","    )\n","    weighted_representation = tf.squeeze(weighted_representation, -2)\n","\n","    # Classify outputs.\n","    logits = layers.Dense(num_classes)(weighted_representation)\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=logits)\n","    return model"],"metadata":{"id":"bE5lV28BTjEW","executionInfo":{"status":"ok","timestamp":1675377929756,"user_tz":360,"elapsed":98,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def run_experiment(model):\n","    optimizer = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.CategoricalCrossentropy(\n","            from_logits=True, label_smoothing=0.1\n","        ),\n","        metrics=[\n","            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n","            keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","        ],\n","    )\n","\n","    checkpoint_filepath = \"/tmp/checkpoint\"\n","    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","        checkpoint_filepath,\n","        monitor=\"val_accuracy\",\n","        save_best_only=True,\n","        save_weights_only=True,\n","    )\n","\n","    history = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=num_epochs,\n","        validation_split=0.1,\n","        callbacks=[checkpoint_callback],\n","    )\n","\n","    model.load_weights(checkpoint_filepath)\n","    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","\n","    return history\n","\n","\n","cct_model = create_cct_model()\n","history = run_experiment(cct_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZB0huV1nTmz2","executionInfo":{"status":"ok","timestamp":1675391946600,"user_tz":360,"elapsed":14010746,"user":{"displayName":"Soonwoo Hong","userId":"01434486630325356504"}},"outputId":"c0fbb5b1-916c-480a-9035-1fc69868c300"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","352/352 [==============================] - 477s 1s/step - loss: 1.8689 - accuracy: 0.3542 - top-5-accuracy: 0.8491 - val_loss: 1.5946 - val_accuracy: 0.4914 - val_top-5-accuracy: 0.9254\n","Epoch 2/30\n","352/352 [==============================] - 463s 1s/step - loss: 1.5575 - accuracy: 0.5069 - top-5-accuracy: 0.9354 - val_loss: 1.4579 - val_accuracy: 0.5534 - val_top-5-accuracy: 0.9562\n","Epoch 3/30\n","352/352 [==============================] - 464s 1s/step - loss: 1.4272 - accuracy: 0.5702 - top-5-accuracy: 0.9536 - val_loss: 1.4411 - val_accuracy: 0.5726 - val_top-5-accuracy: 0.9482\n","Epoch 4/30\n","352/352 [==============================] - 463s 1s/step - loss: 1.3450 - accuracy: 0.6131 - top-5-accuracy: 0.9627 - val_loss: 1.2832 - val_accuracy: 0.6414 - val_top-5-accuracy: 0.9676\n","Epoch 5/30\n","352/352 [==============================] - 465s 1s/step - loss: 1.2879 - accuracy: 0.6416 - top-5-accuracy: 0.9685 - val_loss: 1.2356 - val_accuracy: 0.6628 - val_top-5-accuracy: 0.9752\n","Epoch 6/30\n","352/352 [==============================] - 464s 1s/step - loss: 1.2442 - accuracy: 0.6602 - top-5-accuracy: 0.9716 - val_loss: 1.1961 - val_accuracy: 0.6874 - val_top-5-accuracy: 0.9746\n","Epoch 7/30\n","352/352 [==============================] - 461s 1s/step - loss: 1.2011 - accuracy: 0.6846 - top-5-accuracy: 0.9746 - val_loss: 1.1804 - val_accuracy: 0.6914 - val_top-5-accuracy: 0.9780\n","Epoch 8/30\n","352/352 [==============================] - 459s 1s/step - loss: 1.1704 - accuracy: 0.6954 - top-5-accuracy: 0.9778 - val_loss: 1.2264 - val_accuracy: 0.6684 - val_top-5-accuracy: 0.9740\n","Epoch 9/30\n","352/352 [==============================] - 460s 1s/step - loss: 1.1520 - accuracy: 0.7058 - top-5-accuracy: 0.9783 - val_loss: 1.1470 - val_accuracy: 0.7094 - val_top-5-accuracy: 0.9800\n","Epoch 10/30\n","352/352 [==============================] - 463s 1s/step - loss: 1.1194 - accuracy: 0.7223 - top-5-accuracy: 0.9796 - val_loss: 1.1340 - val_accuracy: 0.7124 - val_top-5-accuracy: 0.9796\n","Epoch 11/30\n","352/352 [==============================] - 464s 1s/step - loss: 1.1042 - accuracy: 0.7297 - top-5-accuracy: 0.9818 - val_loss: 1.1188 - val_accuracy: 0.7242 - val_top-5-accuracy: 0.9808\n","Epoch 12/30\n","352/352 [==============================] - 471s 1s/step - loss: 1.0822 - accuracy: 0.7378 - top-5-accuracy: 0.9825 - val_loss: 1.0962 - val_accuracy: 0.7308 - val_top-5-accuracy: 0.9856\n","Epoch 13/30\n","352/352 [==============================] - 470s 1s/step - loss: 1.0664 - accuracy: 0.7486 - top-5-accuracy: 0.9835 - val_loss: 1.0748 - val_accuracy: 0.7416 - val_top-5-accuracy: 0.9820\n","Epoch 14/30\n","352/352 [==============================] - 469s 1s/step - loss: 1.0568 - accuracy: 0.7496 - top-5-accuracy: 0.9844 - val_loss: 1.0688 - val_accuracy: 0.7480 - val_top-5-accuracy: 0.9816\n","Epoch 15/30\n","352/352 [==============================] - 468s 1s/step - loss: 1.0388 - accuracy: 0.7596 - top-5-accuracy: 0.9868 - val_loss: 1.0566 - val_accuracy: 0.7542 - val_top-5-accuracy: 0.9826\n","Epoch 16/30\n","352/352 [==============================] - 473s 1s/step - loss: 1.0222 - accuracy: 0.7676 - top-5-accuracy: 0.9858 - val_loss: 1.0844 - val_accuracy: 0.7436 - val_top-5-accuracy: 0.9806\n","Epoch 17/30\n","352/352 [==============================] - 468s 1s/step - loss: 1.0176 - accuracy: 0.7686 - top-5-accuracy: 0.9864 - val_loss: 1.0628 - val_accuracy: 0.7524 - val_top-5-accuracy: 0.9820\n","Epoch 18/30\n","352/352 [==============================] - 466s 1s/step - loss: 1.0035 - accuracy: 0.7740 - top-5-accuracy: 0.9881 - val_loss: 1.0421 - val_accuracy: 0.7614 - val_top-5-accuracy: 0.9814\n","Epoch 19/30\n","352/352 [==============================] - 470s 1s/step - loss: 0.9996 - accuracy: 0.7784 - top-5-accuracy: 0.9870 - val_loss: 1.0773 - val_accuracy: 0.7462 - val_top-5-accuracy: 0.9780\n","Epoch 20/30\n","352/352 [==============================] - 471s 1s/step - loss: 0.9888 - accuracy: 0.7821 - top-5-accuracy: 0.9882 - val_loss: 1.0250 - val_accuracy: 0.7656 - val_top-5-accuracy: 0.9850\n","Epoch 21/30\n","352/352 [==============================] - 470s 1s/step - loss: 0.9780 - accuracy: 0.7893 - top-5-accuracy: 0.9889 - val_loss: 1.0268 - val_accuracy: 0.7762 - val_top-5-accuracy: 0.9808\n","Epoch 22/30\n","352/352 [==============================] - 469s 1s/step - loss: 0.9685 - accuracy: 0.7927 - top-5-accuracy: 0.9889 - val_loss: 1.0508 - val_accuracy: 0.7620 - val_top-5-accuracy: 0.9840\n","Epoch 23/30\n","352/352 [==============================] - 473s 1s/step - loss: 0.9598 - accuracy: 0.7953 - top-5-accuracy: 0.9897 - val_loss: 1.0341 - val_accuracy: 0.7700 - val_top-5-accuracy: 0.9852\n","Epoch 24/30\n","352/352 [==============================] - 467s 1s/step - loss: 0.9473 - accuracy: 0.8020 - top-5-accuracy: 0.9901 - val_loss: 1.0253 - val_accuracy: 0.7746 - val_top-5-accuracy: 0.9822\n","Epoch 25/30\n","352/352 [==============================] - 456s 1s/step - loss: 0.9512 - accuracy: 0.8012 - top-5-accuracy: 0.9897 - val_loss: 1.0431 - val_accuracy: 0.7670 - val_top-5-accuracy: 0.9840\n","Epoch 26/30\n","352/352 [==============================] - 459s 1s/step - loss: 0.9384 - accuracy: 0.8055 - top-5-accuracy: 0.9896 - val_loss: 1.0210 - val_accuracy: 0.7740 - val_top-5-accuracy: 0.9838\n","Epoch 27/30\n","352/352 [==============================] - 460s 1s/step - loss: 0.9419 - accuracy: 0.8041 - top-5-accuracy: 0.9902 - val_loss: 0.9783 - val_accuracy: 0.7930 - val_top-5-accuracy: 0.9860\n","Epoch 28/30\n","352/352 [==============================] - 463s 1s/step - loss: 0.9286 - accuracy: 0.8108 - top-5-accuracy: 0.9905 - val_loss: 0.9974 - val_accuracy: 0.7848 - val_top-5-accuracy: 0.9832\n","Epoch 29/30\n","352/352 [==============================] - 463s 1s/step - loss: 0.9266 - accuracy: 0.8133 - top-5-accuracy: 0.9905 - val_loss: 0.9725 - val_accuracy: 0.7902 - val_top-5-accuracy: 0.9848\n","Epoch 30/30\n","352/352 [==============================] - 464s 1s/step - loss: 0.9222 - accuracy: 0.8150 - top-5-accuracy: 0.9909 - val_loss: 1.0080 - val_accuracy: 0.7874 - val_top-5-accuracy: 0.9858\n","313/313 [==============================] - 33s 106ms/step - loss: 1.0050 - accuracy: 0.7816 - top-5-accuracy: 0.9858\n","Test accuracy: 78.16%\n","Test top 5 accuracy: 98.58%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-0F_GT1oToU9"},"execution_count":null,"outputs":[]}]}